knitr::opts_chunk$set(echo = TRUE)
suppressMessages(suppressWarnings({
library(tidymodels)
library(here)
library(palmerpenguins)
library(tidyverse)
}))
# prefer tidymodels functions in any case of name conflict
tidymodels::tidymodels_prefer()
renv::init()
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(suppressWarnings({
library(tidymodels)
library(here)
library(palmerpenguins)
library(tidyverse)
}))
# prefer tidymodels functions in any case of name conflict
tidymodels::tidymodels_prefer()
suppressMessages(suppressWarnings({
library(tidymodels)
library(here)
library(palmerpenguins)
library(tidyverse)
}))
# prefer tidymodels functions in any case of name conflict
tidymodels::tidymodels_prefer()
penguins %>%
filter{!is.na(flipper_length_mm)}%>%
penguins %>%
filter(!is.na(flipper_length_mm))%>%
ggplot(aes(flipper_length_mm, body_mass_g))+
geom_point()+
geom_smooth(method = "lm", se = F)
penguins %>%
filter{!is.na(flipper_length_mm)}%>%
(
penguins %>%
filter(!is.na(flipper_length_mm))%>%
ggplot(aes(flipper_length_mm, body_mass_g))+
geom_point()+
geom_smooth(method = "lm", se = F)
penguins %>%
penguins %>%
filter(!is.na(flipper_length_mm))%>%
ggplot(aes(flipper_length_mm, body_mass_g))+
geom_point()+
geom_smooth(method = "lm", se = F)
##Sflipper\_length\_mm = f(bill\_ depth\_mm) + f(island) + f(body\_mass\_g) + \epsilon$
penguins2 <- penquins
##Sflipper\_length\_mm = f(bill\_ depth\_mm) + f(island) + f(body\_mass\_g) + \epsilon$
penguins2 <- penguins
penguins2 %>%
filter (!is.na(bill_depth_mm)) %>%
ggplot(aes(x = bill_depth_mm, y = flipper_length_mm))+
geom_point()+
geom_smooth (method = "lm", se = F)
penguins <- palmerpenguins::penguins
glimpse(penguins)
penguins %>%
filter(!is.na(bill_length_mm)) %>%
ggplot(aes(x = bill_length_mm, y = flipper_length_mm))+
geom_point()+
geom_smooth(method = "lm", se = F)
##Sflipper\_length\_mm = f(bill\_ depth\_mm) + f(island) + f(body\_mass\_g) + \epsilon$
penguins2 <- penguins
penguins2 %>%
filter (!is.na(bill_depth_mm)) %>%
ggplot(aes(x = bill_depth_mm, y = flipper_length_mm))+
geom_point()+
geom_smooth (method = "lm", se = F)
penguins %>%
select(species) %>%
unique()
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(suppressWarnings({
library(tidymodels)
library(here)
library(palmerpenguins)
library(tidyverse)
library(doParallel)
}))
# prefer tidymodels functions in any case of name conflict
tidymodels::tidymodels_prefer()
## package here is rsample
penguins <- penguins
set.seed(12345)
pen_split <- penguins %>%
initial_split(prop = .8)
# Stratify by species to ensure equal representation
penguins_split_strata <- penguins %>%
initial_split(prop = 0.80, strata = species)
penguins_train <- training(penguins_split_strata)
penguins_test  <-  testing(penguins_split_strata)
install.packages(“doParallel”)
install.packages(“doParallels”)
install.packages(“doParallel”)
install.packages(“doParallel”)
install.packages(c( "foreach", "doParallel") )
install.packages(c("foreach", "doParallel"))
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(suppressWarnings({
library(tidymodels)
library(here)
library(palmerpenguins)
library(tidyverse)
library(doParallel)
}))
# prefer tidymodels functions in any case of name conflict
tidymodels::tidymodels_prefer()
## package here is rsample
penguins <- penguins
set.seed(12345)
pen_split <- penguins %>%
initial_split(prop = .8)
# Stratify by species to ensure equal representation
penguins_split_strata <- penguins %>%
initial_split(prop = 0.80, strata = species)
penguins_train <- training(penguins_split_strata)
penguins_test  <-  testing(penguins_split_strata)
penguins_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_dummy(all_nominal_predictors())
## package here is rsample
penguins <- palmerpenguins::penguins
set.seed(12345)
pen_split <- penguins %>%
initial_split(prop = .8)
# Stratify by species to ensure equal representation
penguins_split_strata <- penguins %>%
initial_split(prop = 0.80, strata = species)
penguins_train <- training(penguins_split_strata)
penguins_test  <-  testing(penguins_split_strata)
penguins_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_dummy(all_nominal_predictors())
penguins_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_dummy(all_nominal_predictors())
penguins_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_dummy(all_nominal_predictors())
penguins_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_dummy(all_nominal_predictors())
library("doPenguin")
library("doParallel")
challenge4_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_dummy(all_nominal_predictors(),
step_normalize())
challenge4_recipe <- step_normalize(
penguins_recipe,
...,
role = NA,
trained = FALSE,
means = NULL,
sds = NULL,
na_rm = TRUE,
skip = FALSE,
id = rand_id("normalize")
)
challenge4_recipe <- step_normalize(
penguins_recipe,
role = NA,
trained = FALSE,
means = NULL,
sds = NULL,
na_rm = TRUE,
skip = FALSE,
id = rand_id("normalize")
)
challenge4_recipe <- step_normalize(
penguins_recipe,
role = NA,
trained = FALSE,
means = NULL,
sds = NULL,
na_rm = TRUE,
skip = FALSE,
)
challenge4_recipe
challenge4_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_normalize(all_numeric_predictors())
challenge4_recipe
# default R
linear_reg() %>%
set_engine("lm")
# glmnet
linear_reg() %>%
set_engine("glmnet")
# Using stan
linear_reg() %>%
set_engine("stan")
lm_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression") %>%
# fit a model by hand as an example
fit(bill_length_mm ~ . , data = penguins_train)
# We can see the model that we created with the summary() method
lm_model %>%
pluck('fit') %>%
summary() %>%
# and we can tidy the output with tidy()
tidy()
class_model <- logistic_reg() %>%
set_engine("glm") %>%
set_mode ("classification") %>%
fit(sex ~ ., data = penguins_train)
prediction_demo <- penguins_test %>%
slice(1:5)
prediction_demo %>%
predict(lm_model, new_data = .)
challenge4_recipe <- recipe(bill_length_mm ~ ., data = penguins_train) %>%
step_normalize(all_numeric_predictors())
linear_reg() %>%
set_engine("lm") %>%
set_mode("regression") %>%
# fit a model by hand as an example
fit(bill_length_mm ~ . , data = bake(prep(challenge4_recipe),penguins_train)) %>%
tidy()
lm_model <-
linear_reg() %>%
set_engine("lm")
penguins_lm_wflow <- workflow() %>%
add_recipe(challenge4_recipe) %>%
add_model(lm_model)
penguins_lm_fit <- fit(penguins_lm_wflow, penguins_train)
# tidy our model fit for readability
penguins_lm_fit %>%
tidy()
# predict new observations of our model fit with predict()
# An additional advantage of the workflow is that we do not have to
# duplicate the preprocessing steps on our test set.
predict(penguins_lm_fit, new_data = penguins_test %>% slice(1:5))
c6_recipe <- recipe(bill_length_mm ~ bill_depth_mm, flipper_length_mm, body_mass_g, data = penguins_train) %>%
step_normalize(all_numeric_predictors())
c6_model <-
linear_reg() %>%
set_engine("lm")
c6_workflow <- workflow() %>%
add_recipe(c6_recipe) %>%
add_model(c6_model)
c6_fit <- fit(c6_workflow, penguins_train)
c6_fit %>%
tidy()
predict(c6_fit, new_data=penguins_test)
c6_recipe <- recipe(bill_length_mm ~ bill_depth_mm, flipper_length_mm, body_mass_g, data = penguins_train) %>%
step_normalize(all_numeric_predictors())
c6_model <-
linear_reg() %>%
set_engine("lm")
c6_workflow <- workflow() %>%
add_recipe(c6_recipe) %>%
add_model(c6_model)
c6_fit <- fit(c6_workflow, penguins_train)
c6_fit %>%
tidy()
predict(c6_fit, new_data=penguins_test)
function(data, truth, ...)
penguins_test_results <- predict(penguins_lm_fit, new_data = penguins_test) %>%
bind_cols(penguins_test %>% select(bill_length_mm))
# We can plot the data prior to computing metrics for a visual inspection of fit
penguins_test_results %>%
ggplot(aes(x = bill_length_mm, y = .pred))+
geom_abline(lty = 2)+
geom_point(alpha = 0.7)+
labs(x = "Bill Length (mm)", y = "Predicted Values")+
coord_obs_pred()
# Make a set of metrics
penguins_metrics <- metric_set(rmse, rsq, mae)
penguins_metrics(penguins_test_results, truth = bill_length_mm, estimate = .pred)
set.seed(1234)
# tidymodels uses v where much of the theoretical literature uses k
# we can also set the replicates of the folds with the repeats argument
penguins_folds <- vfold_cv(penguins_train, v = 10)
penguins_folds
## Perform resampling fits
penguins_cv_res <- penguins_lm_wflow %>%
fit_resamples(resamples = penguins_folds, control = control_resamples(save_pred = TRUE))
## see metrics
penguins_cv_res %>%
collect_metrics()
## Get the assessment set predictions
penguins_cv_res %>%
collect_predictions()
# Create a cluster object and then register:
cl <- makePSOCKcluster(2)
registerDoParallel(cl)
penguins_cv_res <- penguins_lm_wflow %>%
fit_resamples(resamples = penguins_folds, control = control_resamples(save_pred = TRUE))
stopCluster(cl)
## see metrics
penguins_cv_res %>%
collect_metrics()
## Get the assessment set predictions
penguins_cv_res %>%
collect_predictions()
### Run this function afterwards to confirm that computing connections close correctly
unregister_dopar <- function() {
env <- foreach:::.foreachGlobals
rm(list=ls(name=env), pos=env)
}
unregister_dopar()
## First update our recipe
penguins_poly_recipe <- challenge4_recipe %>%
# Step to omit nas. Set skip to true to avoid
# skipping at assessment phase unnecessarily
step_naomit(body_mass_g, skip = TRUE) %>%
step_poly(body_mass_g, degree = tune())
tuned_wflow <- workflow() %>%
add_recipe(penguins_poly_recipe) %>%
add_model(lm_model)
cv_splits <- vfold_cv(penguins_train, v = 10)
degree_grid <- grid_regular(degree(range =c(1,5)), levels = 5)
## resampling specification
tune_res <- tune_grid(
object = tuned_wflow,
resamples = cv_splits,
grid = degree_grid
)
# We can get the average metric value for each parameter combination
tune_res %>%
collect_metrics()
## We can show the best model
tune_res %>%
show_best(metric = "rmse")
